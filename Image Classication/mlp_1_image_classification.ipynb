{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Phx6PhPYqVyx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tf.keras.datasets.mnist.load_data() will return tuples, the tupples structure would look like this\n",
        "# ((training_images, training_labels), (validation_images, validation_labels))\n",
        "\n",
        "(training_images, training_labels),(validation_images, validation_labels) = tf.keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "id": "IfPg7YTOq2Eh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check total files\n",
        "print(f\"training files contain {training_images.shape} images, and {training_labels.shape} labels\")\n",
        "print(f\"training files contain {validation_images.shape} images, and {validation_labels.shape} labels\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzpj8rDmugBe",
        "outputId": "d0071223-327a-4ae5-fa73-018a95b717b4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training files contain (60000, 28, 28) images, and (60000,) labels\n",
            "training files contain (10000, 28, 28) images, and (10000,) labels\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cehck the first umage from the training and validation and check the imaga shape\n",
        "# the images shahpe will be (28,28), we need to expand the dimension to (28,28,1)\n",
        "\n",
        "# for each pixel\n",
        "\n",
        "print(f\"training images shape : {training_images[0].shape}\")\n",
        "print(f\"training images shape : {validation_images[0].shape}\")\n",
        "\n",
        "def reshape_and_normalize(images):\n",
        "    images = images.reshape(*images.shape, 1)/255\n",
        "    return images\n",
        "\n",
        "training_images = reshape_and_normalize(training_images)\n",
        "validation_images = reshape_and_normalize(validation_images)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUvVbjdxr0Iz",
        "outputId": "4dcde939-75f2-47c6-d5bb-f15fde7683e1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training images shape : (28, 28)\n",
            "training images shape : (28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_images2 = reshape_and_normalize(training_images)"
      ],
      "metadata": {
        "id": "GEbiRaFRsCxB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        # Check accuracy\n",
        "        if(logs.get('val_accuracy') > 0.99):\n",
        "            print(\"\\nValidation accuracy is higher than 0.99 so stopping training!\")\n",
        "            self.model.stop_training = True\n",
        ""
      ],
      "metadata": {
        "id": "7peVPhQAs7TF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def convolutional_model():\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "          # Add the same layers as before\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(10, activation='softmax')\n",
        "\n",
        "    ])\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "E0LZ6MC9xix8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = convolutional_model()\n",
        "\n",
        "model_params = model.count_params()\n",
        "\n",
        "assert model_params < 1000000, (\n",
        "    f'Your model has {model_params:,} params. For successful grading, please keep it '\n",
        "    f'under 1,000,000 by reducing the number of units in your Conv2D and/or Dense layers.'\n",
        ")\n",
        "\n",
        "callbacks = myCallback()\n",
        "\n",
        "history = model.fit(training_images, training_labels,\n",
        "                    epochs=10,\n",
        "                    validation_data=(validation_images, validation_labels),\n",
        "                    callbacks=[callbacks])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkGPJ0308fbU",
        "outputId": "273e59c2-adb1-4aeb-84c5-73ce91605ad8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 73s 38ms/step - loss: 0.1449 - accuracy: 0.9551 - val_loss: 0.0492 - val_accuracy: 0.9834\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0469 - accuracy: 0.9852\n",
            "Validation accuracy is higher than 0.99 so stopping training!\n",
            "1875/1875 [==============================] - 67s 36ms/step - loss: 0.0469 - accuracy: 0.9852 - val_loss: 0.0318 - val_accuracy: 0.9902\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gYBrlX9e9wC6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a2mcmwpkKyQu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}